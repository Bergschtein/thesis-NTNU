\documentclass[../../thesis.tex]{subfiles}

\begin{document}

\TODO{relate our work to TimeVQVAE, Neural Representation, Barlow, MaskGIT, }

\TODO{Include something on time series generation / representation learning}


Our work in this thesis can be seen as a tangent of the paper "Vector Quantized Time Series Generation with a Bidirectional Prior Model" \cite{TimeVQVAE}. The TimeVQVAE model is a two staged process. For this part of the thesis we focused on the first stage (tokenization) of the model. Meaning that we did not fit a prior on the latent space, keeping it uniform. Further we simplified the model by not separating the high and low frequency components of the data.\\\\

To our knowledge the joint embedding VQ-VAE models presented in this thesis are new.




\end{document}