
@book{deeplearningbook,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{VQVAE,
  author       = {A{\"{a}}ron van den Oord and
                  Oriol Vinyals and
                  Koray Kavukcuoglu},
  title        = {Neural Discrete Representation Learning},
  journal      = {CoRR},
  volume       = {abs/1711.00937},
  year         = {2017},
  url          = {http://arxiv.org/abs/1711.00937},
  eprinttype    = {arXiv},
  eprint       = {1711.00937},
  timestamp    = {Mon, 13 Aug 2018 16:48:11 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1711-00937.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{TimeVQVAE,
      title={Vector Quantized Time Series Generation with a Bidirectional Prior Model}, 
      author={Daesoo Lee and Sara Malacarne and Erlend Aune},
      year={2023},
      eprint={2303.04743},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@article{VAE,
   title={An Introduction to Variational Autoencoders},
   volume={12},
   ISSN={1935-8245},
   url={http://dx.doi.org/10.1561/2200000056},
   DOI={10.1561/2200000056},
   number={4},
   journal={Foundations and Trends® in Machine Learning},
   publisher={Now Publishers},
   author={Kingma, Diederik P. and Welling, Max},
   year={2019},
   pages={307–392} }


@misc{Rep-rev-persp,
      title={Representation Learning: A Review and New Perspectives}, 
      author={Yoshua Bengio and Aaron Courville and Pascal Vincent},
      year={2014},
      eprint={1206.5538},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{improving-vae-rep,
      title={Improving VAE-based Representation Learning}, 
      author={Mingtian Zhang and Tim Z. Xiao and Brooks Paige and David Barber},
      year={2022},
      eprint={2205.14539},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{chang2022maskgit,
      title={MaskGIT: Masked Generative Image Transformer}, 
      author={Huiwen Chang and Han Zhang and Lu Jiang and Ce Liu and William T. Freeman},
      year={2022},
      eprint={2202.04200},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{VQGAN,
      title={Taming Transformers for High-Resolution Image Synthesis}, 
      author={Patrick Esser and Robin Rombach and Björn Ommer},
      year={2021},
      eprint={2012.09841},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{bardes2022vicreg,
      title={VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning}, 
      author={Adrien Bardes and Jean Ponce and Yann LeCun},
      year={2022},
      eprint={2105.04906},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lee2024vibcreg,
      title={Computer Vision Self-supervised Learning Methods on Time Series}, 
      author={Daesoo Lee and Erlend Aune},
      year={2024},
      eprint={2109.00783},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{siamese,
author = {Bromley, Jane and Guyon, Isabelle and Lecun, Yann and Säckinger, Eduard and Shah, Roopak},
year = {1993},
month = {01},
pages = {737-744},
title = {Signature Verification Using a Siamese Time Delay Neural Network.},
volume = {7},
journal = {International Journal of Pattern Recognition and Artificial Intelligence - IJPRAI}
}

@article{Barlow_origin,
author = {Barlow, Horace},
year = {1961},
month = {01},
pages = {},
title = {Possible Principles Underlying the Transformations of Sensory Messages},
volume = {1},
isbn = {9780262518420},
journal = {Sensory Communication},
doi = {10.7551/mitpress/9780262518420.003.0013}
}

@misc{zbontar2021barlow,
      title={Barlow Twins: Self-Supervised Learning via Redundancy Reduction}, 
      author={Jure Zbontar and Li Jing and Ishan Misra and Yann LeCun and Stéphane Deny},
      year={2021},
      eprint={2103.03230},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{he2015deep,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{zeiler2013visualizing,
      title={Visualizing and Understanding Convolutional Networks}, 
      author={Matthew D Zeiler and Rob Fergus},
      year={2013},
      eprint={1311.2901},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{shin2023exploration,
      title={Exploration into Translation-Equivariant Image Quantization}, 
      author={Woncheol Shin and Gyubok Lee and Jiyoung Lee and Eunyi Lyou and Joonseok Lee and Edward Choi},
      year={2023},
      eprint={2112.00384},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{mcinnes2020umap,
      title={UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}, 
      author={Leland McInnes and John Healy and James Melville},
      year={2020},
      eprint={1802.03426},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{nozawa2022empirical,
      title={Empirical Evaluation and Theoretical Analysis for Representation Learning: A Survey}, 
      author={Kento Nozawa and Issei Sato},
      year={2022},
      eprint={2204.08226},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{grill2020bootstrap,
      title={Bootstrap your own latent: A new approach to self-supervised Learning}, 
      author={Jean-Bastien Grill and Florian Strub and Florent Altché and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Bernardo Avila Pires and Zhaohan Daniel Guo and Mohammad Gheshlaghi Azar and Bilal Piot and Koray Kavukcuoglu and Rémi Munos and Michal Valko},
      year={2020},
      eprint={2006.07733},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{t-SNE,
  author  = {Laurens van der Maaten and Geoffrey Hinton},
  title   = {Visualizing Data using t-SNE},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {86},
  pages   = {2579--2605},
  url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}
@misc{zhang2024selfsupervised,
      title={Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects}, 
      author={Kexin Zhang and Qingsong Wen and Chaoli Zhang and Rongyao Cai and Ming Jin and Yong Liu and James Zhang and Yuxuan Liang and Guansong Pang and Dongjin Song and Shirui Pan},
      year={2024},
      eprint={2306.10125},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Wen_2021, series={IJCAI-2021},
   title={Time Series Data Augmentation for Deep Learning: A Survey},
   url={http://dx.doi.org/10.24963/ijcai.2021/631},
   DOI={10.24963/ijcai.2021/631},
   booktitle={Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence},
   publisher={International Joint Conferences on Artificial Intelligence Organization},
   author={Wen, Qingsong and Sun, Liang and Yang, Fan and Song, Xiaomin and Gao, Jingkun and Wang, Xue and Xu, Huan},
   year={2021},
   month=aug, collection={IJCAI-2021} }

@misc{jing2019selfsupervised,
      title={Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey}, 
      author={Longlong Jing and Yingli Tian},
      year={2019},
      eprint={1902.06162},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lee2021predicting,
      title={Predicting What You Already Know Helps: Provable Self-Supervised Learning}, 
      author={Jason D. Lee and Qi Lei and Nikunj Saunshi and Jiacheng Zhuo},
      year={2021},
      eprint={2008.01064},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{mialon2024variance,
      title={Variance Covariance Regularization Enforces Pairwise Independence in Self-Supervised Representations}, 
      author={Grégoire Mialon and Randall Balestriero and Yann LeCun},
      year={2024},
      eprint={2209.14905},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{huang2019iterative,
      title={Iterative Normalization: Beyond Standardization towards Efficient Whitening}, 
      author={Lei Huang and Yi Zhou and Fan Zhu and Li Liu and Ling Shao},
      year={2019},
      eprint={1904.03441},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{MCCULLOCH199099,
title = {A logical calculus of the ideas immanent in nervous activity},
journal = {Bulletin of Mathematical Biology},
volume = {52},
number = {1},
pages = {99-115},
year = {1990},
issn = {0092-8240},
doi = {https://doi.org/10.1016/S0092-8240(05)80006-0},
url = {https://www.sciencedirect.com/science/article/pii/S0092824005800060},
author = {Warren S. McCulloch and Walter Pitts},
abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.}
}

@book{rosenblatt1957perceptron,
  title={The Perceptron, a Perceiving and Recognizing Automaton Project Para},
  author={Rosenblatt, F.},
  series={Report: Cornell Aeronautical Laboratory},
  url={https://books.google.no/books?id=P_XGPgAACAAJ},
  year={1957},
  publisher={Cornell Aeronautical Laboratory}
}

@article{HORNIK1989359,
title = {Multilayer feedforward networks are universal approximators},
journal = {Neural Networks},
volume = {2},
number = {5},
pages = {359-366},
year = {1989},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
keywords = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.}
}